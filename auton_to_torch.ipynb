{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/TMPredictor/survival_tm/auton-survival\"))\n",
    "from auton_survival.preprocessing import Scaler\n",
    "import optuna\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "#sys.path.append('/projects/EKOLEMEN/survival_tm/train_models/auton-survival')\n",
    "sys.path.append(os.path.expanduser(\"~/TMPredictor/survival_tm/auton-survival\"))\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from auton_survival.estimators import SurvivalModel\n",
    "from auton_survival.metrics import survival_regression_metric\n",
    "from auton_survival.models.dsm.dsm_torch import DeepSurvivalMachinesTorch\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/simple_models.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/x_train_df_normed.pkl', 'rb') as f:\n",
    "    x_train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=179, out_features=1000, bias=False)\n",
      "  (1): ReLU6()\n",
      "  (2): Linear(in_features=1000, out_features=1000, bias=False)\n",
      "  (3): ReLU6()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=3, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=3, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=3, bias=False)\n",
      ")\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = loaded_model._model._gen_torch_model(179, 'Adam', 1)\n",
    "#torch.save(a, 'temp.pth')\n",
    "print(a.embedding)\n",
    "#print(a.act)\n",
    "print(a.shapeg['1'])\n",
    "#print(a.shape['1'].expand(179, -1))\n",
    "print(a.scaleg['1'])\n",
    "#print(a.scale['1'].expand(179, -1))\n",
    "print(a.gate['1'])\n",
    "print(a.temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming 'a' is your original model\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = original_model.embedding\n",
    "        # onnx2keras doesn't support relu6\n",
    "        self.embedding[1] = nn.ReLU()\n",
    "        self.embedding[3] = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class ShapegModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ShapegModel, self).__init__()\n",
    "        self.shapeg = original_model.shapeg['1']  # Access the specific module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.shapeg(x)\n",
    "    \n",
    "class ScalegModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ScalegModel, self).__init__()\n",
    "        self.scaleg = original_model.scaleg['1']  # Access the specific module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.scaleg(x)\n",
    "    \n",
    "class GateModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(GateModel, self).__init__()\n",
    "        self.gate = original_model.gate['1']  # Access the specific module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gate(x)\n",
    "\n",
    "scaleg = ScalegModel(a)\n",
    "gate = GateModel(a)\n",
    "shapeg = ShapegModel(a)\n",
    "embedding = EmbeddingModel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight onnx::MatMul_9 with shape (179, 1000).\n",
      "DEBUG:onnx2keras:Found weight onnx::MatMul_10 with shape (1000, 1000).\n",
      "DEBUG:onnx2keras:Found input input with shape [179]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MatMul\n",
      "DEBUG:onnx2keras:node_name: embedding_embedding.0_MatMul_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::MatMul_9).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM without bias.\n",
      "DEBUG:onnx2keras:gemm:Input units 179, output units 1000.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='embedding_embedding.0_MatMul_output_0/MatMul:0', description=\"created by layer 'embedding_embedding.0_MatMul_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: embedding_embedding.1_Relu_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name embedding_embedding.0_MatMul_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='embedding_embedding.1_Relu_output_0/Relu:0', description=\"created by layer 'embedding_embedding.1_Relu_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MatMul\n",
      "DEBUG:onnx2keras:node_name: embedding_embedding.2_MatMul_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name embedding_embedding.1_Relu_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::MatMul_10).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM without bias.\n",
      "DEBUG:onnx2keras:gemm:Input units 1000, output units 1000.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='embedding_embedding.2_MatMul_output_0/MatMul:0', description=\"created by layer 'embedding_embedding.2_MatMul_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: output\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name embedding_embedding.2_MatMul_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None), name='output/Relu:0', description=\"created by layer 'output'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 179, strides=[179, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_9 : Float(179, 1000, strides=[1, 179], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_10 : Float(1000, 1000, strides=[1, 1000], requires_grad=0, device=cpu)):\n",
      "  %/embedding/embedding.0/MatMul_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/embedding/embedding.0/MatMul\"](%input, %onnx::MatMul_9), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.linear.Linear::embedding.0 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  %/embedding/embedding.1/Relu_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/embedding/embedding.1/Relu\"](%/embedding/embedding.0/MatMul_output_0), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.activation.ReLU::embedding.1 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:1473:0\n",
      "  %/embedding/embedding.2/MatMul_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/embedding/embedding.2/MatMul\"](%/embedding/embedding.1/Relu_output_0, %onnx::MatMul_10), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.linear.Linear::embedding.2 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  %output : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/embedding/embedding.3/Relu\"](%/embedding/embedding.2/MatMul_output_0), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.activation.ReLU::embedding.3 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:1473:0\n",
      "  return (%output)\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# make a dummy input with the correct dimensions for your model\n",
    "dummy_input = torch.randn(1, 179)\n",
    "torch.onnx.export(embedding, dummy_input, 'embedding.onnx', verbose=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return name.lstrip('/').replace('/', '_')\n",
    "\n",
    "def rename_nodes(model):\n",
    "    for node in model.graph.node:\n",
    "        node.name = sanitize_name(node.name)\n",
    "        node.input[:] = [sanitize_name(inp) for inp in node.input]\n",
    "        node.output[:] = [sanitize_name(out) for out in node.output]\n",
    "    for input in model.graph.input:\n",
    "        input.name = sanitize_name(input.name)\n",
    "    for output in model.graph.output:\n",
    "        output.name = sanitize_name(output.name)\n",
    "    for initializer in model.graph.initializer:\n",
    "        initializer.name = sanitize_name(initializer.name)\n",
    "\n",
    "onnx_model = onnx.load('embedding.onnx')\n",
    "rename_nodes(onnx_model)\n",
    "onnx.save(onnx_model, 'sanitized_embedding.onnx')\n",
    "\n",
    "from onnx2keras import onnx_to_keras\n",
    "import onnx\n",
    "onnx_model = onnx.load('sanitized_embedding.onnx')\n",
    "\n",
    "keras_model = onnx_to_keras(onnx_model, ['input'])\n",
    "keras_model.save('embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# convert relu to relu6 in keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ReLU\n",
    "\n",
    "# Assume 'model' is your pre-loaded Keras sequential model\n",
    "for i, layer in enumerate(keras_model.layers):\n",
    "    if isinstance(layer, ReLU):\n",
    "        keras_model.layers[i] = ReLU(max_value=6, name=layer.name)  # Replacing ReLU with ReLU6\n",
    "\n",
    "# Save the updated model if necessary\n",
    "keras_model.save('embedding.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410234, 179)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train_df)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 179])\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.tensor(x_train[0:1]).float()\n",
    "print(x_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.9874, 1.0554, 1.0971]], grad_fn=<AddBackward0>), tensor([[1.1052, 0.9778, 0.9912]], grad_fn=<AddBackward0>), tensor([[ 0.1165,  0.0377, -0.0991]], grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(a(x_train_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9874, 1.0554, 1.0971]], grad_fn=<AddBackward0>) tensor([[1.1052, 0.9778, 0.9912]], grad_fn=<AddBackward0>) tensor([[ 0.1165,  0.0377, -0.0991]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xrep = embedding.forward(x_train_tensor)\n",
    "\n",
    "dim = x_train_tensor.shape[0]\n",
    "print(a.act(shapeg(xrep))+a.shape['1'].expand(dim, -1),\n",
    "           a.act(scaleg(xrep))+a.scale['1'].expand(dim, -1),\n",
    "           gate(xrep)/a.temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 179)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0.98744142 1.05535991 1.097114  ]] [[1.10518538 0.97778107 0.99118527]] [[ 0.11653557  0.03767988 -0.09908683]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "x_train_keras = np.array(x_train_tensor)\n",
    "embedding_keras = load_model('embedding.h5')\n",
    "shapeg_keras = load_model('shapeg.h5')\n",
    "scaleg_keras = load_model('scaleg.h5')\n",
    "gate_keras = load_model('gate.h5')\n",
    "print(x_train_keras.shape)\n",
    "xred_keras = embedding_keras.predict(x_train_keras)\n",
    "\n",
    "print(np.tanh(shapeg_keras.predict(xred_keras))+np.array([1,1,1]), \n",
    "      np.tanh(scaleg_keras.predict(xred_keras))+np.array([1,1,1]),\n",
    "        gate_keras.predict(xred_keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 2 c!\n",
    "from keras2c import k2c\n",
    "\n",
    "k2c(keras_model, 'k2c_model', malloc=False, num_tests=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.9874, 1.0554, 1.0971]], grad_fn=<AddBackward0>), tensor([[1.1052, 0.9778, 0.9912]], grad_fn=<AddBackward0>), tensor([[ 0.1165,  0.0377, -0.0991]], grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "b = torch.load('temp.pth')\n",
    "print(b.forward(x_train_tensor.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lognormal_cdf(model, x, t_horizon, risk='1'):\n",
    "\n",
    "  squish = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  shape, scale, logits = model.forward(x, risk)\n",
    "  logits = squish(logits)\n",
    "\n",
    "  k_ = shape\n",
    "  b_ = scale\n",
    "\n",
    "  t_horz = torch.tensor(t_horizon).double().to(logits.device)\n",
    "  t_horz = t_horz.repeat(shape.shape[0], 1)\n",
    "\n",
    "  cdfs = []\n",
    "\n",
    "  # for j in range(len(t_horizon)):\n",
    "  for j in range(t_horz.shape[1]):\n",
    "\n",
    "    t = t_horz[:, j]\n",
    "    lcdfs = []\n",
    "\n",
    "    for g in range(model.k):\n",
    "\n",
    "      mu = k_[:, g]\n",
    "      sigma = b_[:, g]\n",
    "\n",
    "      s = torch.div(torch.log(t) - mu, torch.exp(sigma)*np.sqrt(2))\n",
    "      s = 0.5 - 0.5*torch.erf(s)\n",
    "      s = torch.log(s)\n",
    "      lcdfs.append(s)\n",
    "\n",
    "    lcdfs = torch.stack(lcdfs, dim=1)\n",
    "    lcdfs = lcdfs+logits\n",
    "    lcdfs = torch.logsumexp(lcdfs, dim=1)\n",
    "    cdfs.append(lcdfs.detach().cpu().numpy())\n",
    "\n",
    "  return cdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
