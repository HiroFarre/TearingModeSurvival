{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/TMPredictor/survival_tm/auton-survival\"))\n",
    "from auton_survival.preprocessing import Scaler\n",
    "import optuna\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "#sys.path.append('/projects/EKOLEMEN/survival_tm/train_models/auton-survival')\n",
    "sys.path.append(os.path.expanduser(\"~/TMPredictor/survival_tm/auton-survival\"))\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from auton_survival.estimators import SurvivalModel\n",
    "from auton_survival.metrics import survival_regression_metric\n",
    "from auton_survival.models.dsm.dsm_torch import DeepSurvivalMachinesTorch\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open('models/pca_hyperparams.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)[1][0]'''\n",
    "with open('models/dummy.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/x_train_pca.pkl', 'rb') as f:\n",
    "    x_train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=38, out_features=10, bias=False)\n",
      "  (1): ReLU6()\n",
      "  (2): Linear(in_features=10, out_features=50, bias=False)\n",
      "  (3): ReLU6()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=False)\n",
      ")\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = loaded_model._model._gen_torch_model(38, 'Adam', 1)\n",
    "#torch.save(a, 'temp.pth')\n",
    "print(a.embedding)\n",
    "#print(a.act)\n",
    "print(a.shapeg['1'])\n",
    "#print(a.shape['1'].expand(179, -1))\n",
    "print(a.scaleg['1'])\n",
    "#print(a.scale['1'].expand(179, -1))\n",
    "print(a.gate['1'])\n",
    "print(a.temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming 'a' is your original model\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = original_model.embedding\n",
    "        # onnx2keras doesn't support relu6\n",
    "        self.embedding[1] = nn.ReLU()\n",
    "        self.embedding[3] = nn.ReLU()\n",
    "        #self.embedding[5] = nn.ReLU()\n",
    "        #self.embedding[7] = nn.ReLU()\n",
    "        #self.embedding[9] = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "class ShapegModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ShapegModel, self).__init__()\n",
    "        self.shapeg = original_model.shapeg['1']  # Access the specific module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.shapeg(x)\n",
    "    \n",
    "class ScalegModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ScalegModel, self).__init__()\n",
    "        self.scaleg = original_model.scaleg['1']  # Access the specific module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.scaleg(x)\n",
    "    \n",
    "class GateModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(GateModel, self).__init__()\n",
    "        self.gate = original_model.gate['1']  # Access the specific module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gate(x)\n",
    "\n",
    "scaleg = ScalegModel(a)\n",
    "gate = GateModel(a)\n",
    "shapeg = ShapegModel(a)\n",
    "embedding = EmbeddingModel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight onnx::MatMul_9 with shape (38, 10).\n",
      "DEBUG:onnx2keras:Found weight onnx::MatMul_10 with shape (10, 50).\n",
      "DEBUG:onnx2keras:Found input input with shape [38]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MatMul\n",
      "DEBUG:onnx2keras:node_name: embedding_embedding_0_MatMul_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::MatMul_9).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM without bias.\n",
      "DEBUG:onnx2keras:gemm:Input units 38, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='embedding_embedding_0_MatMul_output_0/MatMul:0', description=\"created by layer 'embedding_embedding_0_MatMul_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: embedding_embedding_1_Relu_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name embedding_embedding_0_MatMul_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='embedding_embedding_1_Relu_output_0/Relu:0', description=\"created by layer 'embedding_embedding_1_Relu_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MatMul\n",
      "DEBUG:onnx2keras:node_name: embedding_embedding_2_MatMul_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name embedding_embedding_1_Relu_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::MatMul_10).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM without bias.\n",
      "DEBUG:onnx2keras:gemm:Input units 10, output units 50.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='embedding_embedding_2_MatMul_output_0/MatMul:0', description=\"created by layer 'embedding_embedding_2_MatMul_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: output\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name embedding_embedding_2_MatMul_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='output/Relu:0', description=\"created by layer 'output'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 38, strides=[38, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_9 : Float(38, 10, strides=[1, 38], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_10 : Float(10, 50, strides=[1, 10], requires_grad=0, device=cpu)):\n",
      "  %/embedding/embedding.0/MatMul_output_0 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/embedding/embedding.0/MatMul\"](%input, %onnx::MatMul_9), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.linear.Linear::embedding.0 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  %/embedding/embedding.1/Relu_output_0 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/embedding/embedding.1/Relu\"](%/embedding/embedding.0/MatMul_output_0), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.activation.ReLU::embedding.1 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:1473:0\n",
      "  %/embedding/embedding.2/MatMul_output_0 : Float(1, 50, strides=[50, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/embedding/embedding.2/MatMul\"](%/embedding/embedding.1/Relu_output_0, %onnx::MatMul_10), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.linear.Linear::embedding.2 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  %output : Float(1, 50, strides=[50, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/embedding/embedding.3/Relu\"](%/embedding/embedding.2/MatMul_output_0), scope: __main__.EmbeddingModel::/torch.nn.modules.container.Sequential::embedding/torch.nn.modules.activation.ReLU::embedding.3 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:1473:0\n",
      "  return (%output)\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# make a dummy input with the correct dimensions for your model\n",
    "dummy_input = torch.randn(1, 38)\n",
    "torch.onnx.export(embedding, dummy_input, 'embedding.onnx', verbose=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return name.lstrip('/').replace('/', '_').replace('.', '_')\n",
    "\n",
    "def rename_nodes(model):\n",
    "    for node in model.graph.node:\n",
    "        node.name = sanitize_name(node.name)\n",
    "        node.input[:] = [sanitize_name(inp) for inp in node.input]\n",
    "        node.output[:] = [sanitize_name(out) for out in node.output]\n",
    "    for input in model.graph.input:\n",
    "        input.name = sanitize_name(input.name)\n",
    "    for output in model.graph.output:\n",
    "        output.name = sanitize_name(output.name)\n",
    "    for initializer in model.graph.initializer:\n",
    "        initializer.name = sanitize_name(initializer.name)\n",
    "\n",
    "onnx_model = onnx.load('embedding.onnx')\n",
    "rename_nodes(onnx_model)\n",
    "onnx.save(onnx_model, 'sanitized_embedding.onnx')\n",
    "\n",
    "from onnx2keras import onnx_to_keras\n",
    "import onnx\n",
    "onnx_model = onnx.load('sanitized_embedding.onnx')\n",
    "\n",
    "keras_model = onnx_to_keras(onnx_model, ['input'])\n",
    "keras_model.save('tape_dummy_embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# convert relu to relu6 in keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ReLU\n",
    "\n",
    "# Assume 'model' is your pre-loaded Keras sequential model\n",
    "for i, layer in enumerate(keras_model.layers):\n",
    "    if isinstance(layer, ReLU):\n",
    "        keras_model.layers[i] = ReLU(max_value=6, name=layer.name)  # Replacing ReLU with ReLU6\n",
    "\n",
    "# Save the updated model if necessary\n",
    "keras_model.save('tape_dummy_embedding.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight scaleg_0_weight with shape (10, 50).\n",
      "DEBUG:onnx2keras:Found weight scaleg_0_bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found input input with shape [50]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input).\n",
      "DEBUG:onnx2keras:Check input 1 (name scaleg_0_weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name scaleg_0_bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 50, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='output/BiasAdd:0', description=\"created by layer 'output'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 50, strides=[50, 1], requires_grad=0, device=cpu),\n",
      "      %scaleg.0.weight : Float(10, 50, strides=[50, 1], requires_grad=1, device=cpu),\n",
      "      %scaleg.0.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %output : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/scaleg/scaleg.0/Gemm\"](%input, %scaleg.0.weight, %scaleg.0.bias), scope: __main__.ScalegModel::/torch.nn.modules.container.Sequential::scaleg/torch.nn.modules.linear.Linear::scaleg.0 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  return (%output)\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# make a dummy input with the correct dimensions for your model\n",
    "dummy_input = torch.randn(1, 50)\n",
    "torch.onnx.export(scaleg, dummy_input, 'scaleg.onnx', verbose=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return name.lstrip('/').replace('/', '_').replace('.', '_')\n",
    "\n",
    "def rename_nodes(model):\n",
    "    for node in model.graph.node:\n",
    "        node.name = sanitize_name(node.name)\n",
    "        node.input[:] = [sanitize_name(inp) for inp in node.input]\n",
    "        node.output[:] = [sanitize_name(out) for out in node.output]\n",
    "    for input in model.graph.input:\n",
    "        input.name = sanitize_name(input.name)\n",
    "    for output in model.graph.output:\n",
    "        output.name = sanitize_name(output.name)\n",
    "    for initializer in model.graph.initializer:\n",
    "        initializer.name = sanitize_name(initializer.name)\n",
    "\n",
    "onnx_model = onnx.load('scaleg.onnx')\n",
    "rename_nodes(onnx_model)\n",
    "onnx.save(onnx_model, 'sanitized_scaleg.onnx')\n",
    "\n",
    "from onnx2keras import onnx_to_keras\n",
    "import onnx\n",
    "onnx_model = onnx.load('sanitized_scaleg.onnx')\n",
    "\n",
    "keras_model = onnx_to_keras(onnx_model, ['input'])\n",
    "keras_model.save('tape_dummy_scaleg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight shapeg_0_weight with shape (10, 50).\n",
      "DEBUG:onnx2keras:Found weight shapeg_0_bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found input input with shape [50]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input).\n",
      "DEBUG:onnx2keras:Check input 1 (name shapeg_0_weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name shapeg_0_bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 50, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='output/BiasAdd:0', description=\"created by layer 'output'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 50, strides=[50, 1], requires_grad=0, device=cpu),\n",
      "      %shapeg.0.weight : Float(10, 50, strides=[50, 1], requires_grad=1, device=cpu),\n",
      "      %shapeg.0.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %output : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/shapeg/shapeg.0/Gemm\"](%input, %shapeg.0.weight, %shapeg.0.bias), scope: __main__.ShapegModel::/torch.nn.modules.container.Sequential::shapeg/torch.nn.modules.linear.Linear::shapeg.0 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  return (%output)\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# make a dummy input with the correct dimensions for your model\n",
    "dummy_input = torch.randn(1, 50)\n",
    "torch.onnx.export(shapeg, dummy_input, 'shapeg.onnx', verbose=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return name.lstrip('/').replace('/', '_').replace('.', '_')\n",
    "\n",
    "def rename_nodes(model):\n",
    "    for node in model.graph.node:\n",
    "        node.name = sanitize_name(node.name)\n",
    "        node.input[:] = [sanitize_name(inp) for inp in node.input]\n",
    "        node.output[:] = [sanitize_name(out) for out in node.output]\n",
    "    for input in model.graph.input:\n",
    "        input.name = sanitize_name(input.name)\n",
    "    for output in model.graph.output:\n",
    "        output.name = sanitize_name(output.name)\n",
    "    for initializer in model.graph.initializer:\n",
    "        initializer.name = sanitize_name(initializer.name)\n",
    "\n",
    "onnx_model = onnx.load('shapeg.onnx')\n",
    "rename_nodes(onnx_model)\n",
    "onnx.save(onnx_model, 'sanitized_shapeg.onnx')\n",
    "\n",
    "from onnx2keras import onnx_to_keras\n",
    "import onnx\n",
    "onnx_model = onnx.load('sanitized_shapeg.onnx')\n",
    "\n",
    "keras_model = onnx_to_keras(onnx_model, ['input'])\n",
    "keras_model.save('tape_dummy_shapeg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight onnx::MatMul_4 with shape (50, 10).\n",
      "DEBUG:onnx2keras:Found input input with shape [50]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MatMul\n",
      "DEBUG:onnx2keras:node_name: output\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::MatMul_4).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM without bias.\n",
      "DEBUG:onnx2keras:gemm:Input units 50, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='output/MatMul:0', description=\"created by layer 'output'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 50, strides=[50, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_4 : Float(50, 10, strides=[1, 50], requires_grad=0, device=cpu)):\n",
      "  %output : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/gate/gate.0/MatMul\"](%input, %onnx::MatMul_4), scope: __main__.GateModel::/torch.nn.modules.container.Sequential::gate/torch.nn.modules.linear.Linear::gate.0 # /home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  return (%output)\n",
      "\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# make a dummy input with the correct dimensions for your model\n",
    "dummy_input = torch.randn(1, 50)\n",
    "torch.onnx.export(gate, dummy_input, 'gate.onnx', verbose=True, input_names = ['input'], output_names = ['output'])\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return name.lstrip('/').replace('/', '_').replace('.', '_')\n",
    "\n",
    "def rename_nodes(model):\n",
    "    for node in model.graph.node:\n",
    "        node.name = sanitize_name(node.name)\n",
    "        node.input[:] = [sanitize_name(inp) for inp in node.input]\n",
    "        node.output[:] = [sanitize_name(out) for out in node.output]\n",
    "    for input in model.graph.input:\n",
    "        input.name = sanitize_name(input.name)\n",
    "    for output in model.graph.output:\n",
    "        output.name = sanitize_name(output.name)\n",
    "    for initializer in model.graph.initializer:\n",
    "        initializer.name = sanitize_name(initializer.name)\n",
    "\n",
    "onnx_model = onnx.load('gate.onnx')\n",
    "rename_nodes(onnx_model)\n",
    "onnx.save(onnx_model, 'sanitized_gate.onnx')\n",
    "\n",
    "from onnx2keras import onnx_to_keras\n",
    "import onnx\n",
    "onnx_model = onnx.load('sanitized_gate.onnx')\n",
    "\n",
    "keras_model = onnx_to_keras(onnx_model, ['input'])\n",
    "keras_model.save('tape_dummy_gate.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OUTPUT CORRECTNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/rt_x_train_pca.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open('data/rt_e.pkl', 'rb') as f:\n",
    "    e = np.array(pickle.load(f))\n",
    "with open('data/rt_t.pkl', 'rb') as f:\n",
    "    t = np.array(pickle.load(f))\n",
    "with open('data/rt_shots.pkl', 'rb') as f:\n",
    "    shots_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/pca_hyperparams.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)[1][0]\n",
    "\n",
    "model = loaded_model._model._gen_torch_model(34, 'Adam', 1)\n",
    "\n",
    "embedding = model.embedding\n",
    "shapeg = a.shapeg['1']\n",
    "scaleg = a.scaleg['1']\n",
    "gate = a.gate['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.values).float()\n",
    "wanted_shot = '193348'\n",
    "start_index = shots_list.index(wanted_shot)\n",
    "end_index = len(shots_list) - 1 - shots_list[::-1].index(wanted_shot)\n",
    "\n",
    "\n",
    "wanted_x_train_tensor = x_train_tensor[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('180636_outputs.pkl', 'wb') as f:\\n    pickle.dump([wanted_x_train_tensor, model_output, embedding_output, shapeg_output, scaleg_output, gate_output, survival_output], f)\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_output = model(wanted_x_train_tensor)\n",
    "embedding_output = embedding(wanted_x_train_tensor)\n",
    "shapeg_output = shapeg(embedding_output)\n",
    "scaleg_output = scaleg(embedding_output)\n",
    "gate_output = gate(embedding_output)\n",
    "plt.plot(loaded_model._model.predict_survival(np.array(wanted_x_train_tensor).astype(float), [400]))\n",
    "plt.ylim(0, 1)\n",
    "'''with open('180636_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump([wanted_x_train_tensor, model_output, embedding_output, shapeg_output, scaleg_output, gate_output, survival_output], f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n",
      "torch.Size([1, 3])\n",
      "tensor([[0.9874, 1.0554, 1.0971]], grad_fn=<AddBackward0>) tensor([[1.1052, 0.9778, 0.9912]], grad_fn=<AddBackward0>) tensor([[ 0.1165,  0.0377, -0.0991]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xrep = embedding.forward(wanted_x_train_tensor)\n",
    "dim = x_train_tensor.shape[0]\n",
    "print(a.act(shapeg(xrep))+a.shape['1'].expand(dim, -1),\n",
    "           a.act(scaleg(xrep))+a.scale['1'].expand(dim, -1),\n",
    "           gate(xrep)/a.temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 179)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0.98744142 1.05535991 1.097114  ]] [[1.10518538 0.97778107 0.99118527]] [[ 0.11653557  0.03767988 -0.09908683]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "x_train_keras = np.array(x_train_tensor)\n",
    "embedding_keras = load_model('embedding.h5')\n",
    "shapeg_keras = load_model('shapeg.h5')\n",
    "scaleg_keras = load_model('scaleg.h5')\n",
    "gate_keras = load_model('gate.h5')\n",
    "print(x_train_keras.shape)\n",
    "xred_keras = embedding_keras.predict(x_train_keras)\n",
    "\n",
    "print(np.tanh(shapeg_keras.predict(xred_keras))+np.array([1,1,1]), \n",
    "      np.tanh(scaleg_keras.predict(xred_keras))+np.array([1,1,1]),\n",
    "        gate_keras.predict(xred_keras))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
