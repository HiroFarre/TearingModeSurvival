{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf8585/.conda/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/TMPredictor/survival_tm/auton-survival\"))\n",
    "from auton_survival.preprocessing import Scaler\n",
    "import optuna\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "#sys.path.append('/projects/EKOLEMEN/survival_tm/train_models/auton-survival')\n",
    "sys.path.append(os.path.expanduser(\"~/TMPredictor/survival_tm/auton-survival\"))\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from auton_survival.estimators import SurvivalModel\n",
    "from auton_survival.metrics import survival_regression_metric\n",
    "from auton_survival.models.dsm import DeepSurvivalMachines\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('data/x_train_df_normed.pkl', 'wb') as f:\\n    pickle.dump(x_train_df_normed, f)\\nwith open('data/x_valid_df_normed.pkl', 'wb') as f:\\n    pickle.dump(x_valid_df_normed, f)\\nwith open('data/x_test_df_normed.pkl', 'wb') as f:\\n    pickle.dump(x_test_df_normed, f)\\nwith open('data/outcomes_valid_df.pkl', 'wb') as f:\\n    pickle.dump(outcomes_valid_df, f)\\nwith open('data/outcomes_train_df.pkl', 'wb') as f:\\n    pickle.dump(outcomes_train_df, f)\\nwith open('data/outcomes_test_df.pkl', 'wb') as f:\\n    pickle.dump(outcomes_test_df, f)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shots = np.load('/projects/EKOLEMEN/survival_tm/shots.npy')\n",
    "tm_shots = np.load('/projects/EKOLEMEN/survival_tm/tm_shots.npy')\n",
    "st_shots = np.load('/projects/EKOLEMEN/survival_tm/st_shots.npy')\n",
    "\n",
    "def load_data(data_type):\n",
    "    with open(f'/projects/EKOLEMEN/survival_tm/formatted_labels/{data_type}.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    return data['x'], data['t'], data['e']\n",
    "\n",
    "# Don't want whole dataset right now so 0.5 factor to reduce\n",
    "n = len(shots)\n",
    "\n",
    "tr_size = int(n*0.80)\n",
    "vl_size = int(n*0.10)\n",
    "te_size = int(n*0.10)\n",
    "\n",
    "train_shots = shots[:tr_size]\n",
    "test_shots = shots[-te_size:]\n",
    "valid_shots = shots[tr_size:tr_size+vl_size]\n",
    "\n",
    "x_train, t_train, e_train = load_data('train')\n",
    "x_test,  t_test,  e_test  = load_data('test')\n",
    "x_valid, t_valid, e_valid = load_data('valid')\n",
    "\n",
    "# Get inds for time <600ms\n",
    "# is this needed? Not sure.\n",
    "'''inds = np.where(t_train < 600)[0]\n",
    "\n",
    "x_train = x_train[inds]\n",
    "t_train = t_train[inds]\n",
    "e_train = e_train[inds]'''\n",
    "\n",
    "tm_inds = np.where(e_train == 1)[0]\n",
    "st_inds = np.where(e_train == 0)[0]\n",
    "new_st_inds = np.random.choice(st_inds, size=len(tm_inds), replace=False)\n",
    "combined_inds = np.concatenate((tm_inds, new_st_inds))\n",
    "sorted_combined_inds = np.sort(combined_inds)\n",
    "\n",
    "x_train = x_train[sorted_combined_inds]\n",
    "t_train = t_train[sorted_combined_inds]\n",
    "e_train = e_train[sorted_combined_inds]\n",
    "\n",
    "'''x_train = np.concatenate((x_train[tm_inds], x_train[new_st_inds]), axis=0)\n",
    "t_train = np.concatenate((t_train[tm_inds], t_train[new_st_inds]), axis=0)\n",
    "e_train = np.concatenate((e_train[tm_inds], e_train[new_st_inds]), axis=0)\n",
    "plt.plot(t_train[10000:11000])\n",
    "# Shuffle arrays because currently all 1s followed by all 0s\n",
    "p = np.random.permutation(len(t_train))\n",
    "x_train = x_train[p,:]\n",
    "t_train = t_train[p]\n",
    "e_train = e_train[p]'''\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "t_train_df = pd.DataFrame(t_train)\n",
    "e_train_df = pd.DataFrame(e_train)\n",
    "\n",
    "x_valid_df = pd.DataFrame(x_valid)\n",
    "t_valid_df = pd.DataFrame(t_valid)\n",
    "e_valid_df = pd.DataFrame(e_valid)\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "t_test_df = pd.DataFrame(t_test)\n",
    "e_test_df = pd.DataFrame(e_test)\n",
    "\n",
    "outcomes_valid_df = pd.DataFrame({'time': t_valid, 'event': e_valid})\n",
    "\n",
    "outcomes_train_df = pd.DataFrame({'time': t_train, 'event': e_train})\n",
    "outcomes_test_df = pd.DataFrame({'time': t_test, 'event': e_test})\n",
    "#normalize\n",
    "scaler = Scaler()\n",
    "transformer = scaler.fit(x_train_df)\n",
    "x_train_df_normed = transformer.transform(x_train_df)\n",
    "x_valid_df_normed = transformer.transform(x_valid_df)\n",
    "x_test_df_normed = transformer.transform(x_test_df)\n",
    "\n",
    "'''with open('data/x_train_df_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train_df_normed, f)\n",
    "with open('data/x_valid_df_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_valid_df_normed, f)\n",
    "with open('data/x_test_df_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test_df_normed, f)\n",
    "with open('data/outcomes_valid_df.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_valid_df, f)\n",
    "with open('data/outcomes_train_df.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_train_df, f)\n",
    "with open('data/outcomes_test_df.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_test_df, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we give each timestep all the info from a few timesteps in the past. \n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "t_train_np = np.array(t_train)[4:]\n",
    "e_train_np = np.array(e_train)[4:]\n",
    "\n",
    "x_valid_np = np.array(x_valid)\n",
    "t_valid_np = np.array(t_valid)[4:]\n",
    "e_valid_np = np.array(e_valid)[4:]\n",
    "\n",
    "x_test_np = np.array(x_test)\n",
    "t_test_np = np.array(t_test)[4:]\n",
    "e_test_np = np.array(e_test)[4:]\n",
    "\n",
    "outcomes_valid_memory = pd.DataFrame({'time': t_valid_np, 'event': e_valid_np})\n",
    "outcomes_test_memory = pd.DataFrame({'time': t_test_np, 'event': e_test_np})\n",
    "outcomes_train_memory = pd.DataFrame({'time': t_train_np, 'event': e_train_np})\n",
    "\n",
    "x_valid_memory = np.array([x_valid_np[i-4:i+1].flatten() for i in range(4, len(x_valid_np))])\n",
    "x_test_memory = np.array([x_test_np[i-4:i+1].flatten() for i in range(4, len(x_test_np))])\n",
    "x_train_memory = np.array([x_train_np[i-4:i+1].flatten() for i in range(4, len(x_train_np))])\n",
    "\n",
    "train_peaks = np.array(find_peaks_in_data(np.array(outcomes_train_memory['time'])))\n",
    "valid_peaks = np.array(find_peaks_in_data(np.array(outcomes_valid_memory['time'])))\n",
    "test_peaks = np.array(find_peaks_in_data(np.array(outcomes_test_memory['time'])))\n",
    "\n",
    "new_train_peaks = np.sort(np.concatenate((train_peaks, train_peaks+1, train_peaks+2, train_peaks+3)))\n",
    "new_valid_peaks = np.sort(np.concatenate((valid_peaks, valid_peaks+1, valid_peaks+2, valid_peaks+3)))\n",
    "new_test_peaks = np.sort(np.concatenate((test_peaks, test_peaks+1, test_peaks+2, test_peaks+3)))\n",
    "\n",
    "\n",
    "x_valid_memory = pd.DataFrame(np.delete(x_valid_memory, new_valid_peaks, axis=0))\n",
    "x_test_memory = pd.DataFrame(np.delete(x_test_memory, new_test_peaks, axis=0))\n",
    "x_train_memory = pd.DataFrame(np.delete(x_train_memory, new_train_peaks, axis=0))\n",
    "\n",
    "scaler = Scaler()\n",
    "transformer = scaler.fit(x_train_memory)\n",
    "x_train_memory_normed = transformer.transform(x_train_memory)\n",
    "x_valid_memory_normed = transformer.transform(x_valid_memory)\n",
    "x_test_memory_normed = transformer.transform(x_test_memory)\n",
    "\n",
    "with open('data/x_valid_memory_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_valid_memory_normed, f)\n",
    "with open('data/x_test_memory_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test_memory_normed, f)\n",
    "with open('data/x_train_memory_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train_memory_normed, f)\n",
    "with open('data/outcomes_valid_memory.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_valid_memory, f)\n",
    "with open('data/outcomes_train_memory.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_train_memory, f)\n",
    "with open('data/outcomes_test_memory.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_test_memory, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_peaks[0])\n",
    "print(t_train_np[16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['pinj', 'tinj', 'betan_EFIT01', 'qmin_EFIT01', 'ech_pwr_total', 'ip', 'bt', 'li_EFIT01', 'aminor_EFIT01', \n",
    "          'rmaxis_EFIT01', 'tribot_EFIT01', 'tritop_EFIT01', 'kappa_EFIT01', 'volume_EFIT01']\n",
    "\n",
    "# we give each timestep all the info from a few timesteps in the past. \n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "t_train_np = np.array(t_train)[:-4]\n",
    "e_train_np = np.array(e_train)[:-4]\n",
    "\n",
    "x_valid_np = np.array(x_valid)\n",
    "t_valid_np = np.array(t_valid)[:-4]\n",
    "e_valid_np = np.array(e_valid)[:-4]\n",
    "\n",
    "x_test_np = np.array(x_test)\n",
    "t_test_np = np.array(t_test)[:-4]\n",
    "e_test_np = np.array(e_test)[:-4]\n",
    "\n",
    "outcomes_valid_future = pd.DataFrame({'time': t_valid_np, 'event': e_valid_np})\n",
    "outcomes_test_future = pd.DataFrame({'time': t_test_np, 'event': e_test_np})\n",
    "outcomes_train_future = pd.DataFrame({'time': t_train_np, 'event': e_train_np})\n",
    "\n",
    "# we keep the present and 4 in the future\n",
    "x_valid_future = pd.DataFrame([np.concatenate((x_valid_np[i:i+5, 0:len(signals)].flatten(), x_valid_np[i, len(signals):])) for i in range(len(x_valid_np)-4)])\n",
    "x_test_future = pd.DataFrame([np.concatenate((x_test_np[i:i+5, 0:len(signals)].flatten(), x_test_np[i, len(signals):])) for i in range(len(x_test_np)-4)])\n",
    "x_train_future = pd.DataFrame([np.concatenate((x_train_np[i:i+5, 0:len(signals)].flatten(), x_train_np[i, len(signals):])) for i in range(len(x_train_np)-4)])\n",
    "\n",
    "train_peaks = np.array(find_peaks_in_data(np.array(outcomes_train_future['time'])))\n",
    "valid_peaks = np.array(find_peaks_in_data(np.array(outcomes_valid_future['time'])))\n",
    "test_peaks = np.array(find_peaks_in_data(np.array(outcomes_test_future['time'])))\n",
    "\n",
    "new_train_peaks = np.sort(np.concatenate((train_peaks-1, train_peaks-2, train_peaks-3, train_peaks-4)))\n",
    "new_valid_peaks = np.sort(np.concatenate((valid_peaks-1, valid_peaks-2, valid_peaks-3, valid_peaks-4)))\n",
    "new_test_peaks = np.sort(np.concatenate((test_peaks-1, test_peaks-2, test_peaks-3, test_peaks-4)))\n",
    "\n",
    "x_valid_future = pd.DataFrame(np.delete(x_valid_future, new_valid_peaks, axis=0))\n",
    "x_test_future = pd.DataFrame(np.delete(x_test_future, new_test_peaks, axis=0))\n",
    "x_train_future = pd.DataFrame(np.delete(x_train_future, new_train_peaks, axis=0))\n",
    "\n",
    "scaler = Scaler()\n",
    "transformer = scaler.fit(x_train_future)\n",
    "x_train_future_normed = transformer.transform(x_train_future)\n",
    "x_valid_future_normed = transformer.transform(x_valid_future)\n",
    "x_test_future_normed = transformer.transform(x_test_future)\n",
    "\n",
    "with open('data/x_valid_future_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_valid_future_normed, f)\n",
    "with open('data/x_test_future_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test_future_normed, f)\n",
    "with open('data/x_train_future_normed.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train_future_normed, f)\n",
    "with open('data/outcomes_valid_future.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_valid_future, f)\n",
    "with open('data/outcomes_train_future.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_train_future, f)\n",
    "with open('data/outcomes_test_future.pkl', 'wb') as f:\n",
    "    pickle.dump(outcomes_test_future, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make WTC curve\n",
    "\n",
    "# one issue with this metric is if we never predict TMs then we're always perfect. \n",
    "def fpr_auc(model, normed_x, normed_t, normed_e, prediction_times, threshold=0.7):\n",
    "    out_survival = model.predict_survival(normed_x, prediction_times)\n",
    "    fprs = []\n",
    "    for i, time in enumerate(prediction_times):\n",
    "        survival_prediction = out_survival[:,i]\n",
    "        survival_prediction = (survival_prediction < threshold).astype(int)\n",
    "        false_positives = np.logical_and(survival_prediction == 1, normed_e == 0)\n",
    "        true_negatives = np.logical_and(survival_prediction == 0, normed_e == 0)\n",
    "        fpr = false_positives.sum() / (false_positives.sum() + true_negatives.sum())\n",
    "        fprs.append(fpr)\n",
    "\n",
    "    auc = np.trapz(fprs, prediction_times)\n",
    "    return auc, fprs, prediction_times\n",
    "\n",
    "def find_peaks_in_data(data):\n",
    "    peaks = []\n",
    "    for i in range(1, len(data) - 1):\n",
    "        if data[i-1] < data[i] > data[i+1]:\n",
    "            peaks.append(i)\n",
    "    return peaks\n",
    "\n",
    "def fnr_auc(model, normed_x, normed_t, normed_e, prediction_times, threshold=0.7):\n",
    "    out_survival = model.predict_survival(normed_x, prediction_times)\n",
    "    fnrs = []\n",
    "    fprs = []\n",
    "    shot_indices = find_peaks_in_data(normed_t)\n",
    "    for i, time in enumerate(prediction_times):\n",
    "        tm_prediction_per_shot = []\n",
    "        # 1 means correct TM prediction, 0 means unpredicted TM, -1 means no TM in shot and no TM predicted, -2 means no TM in shot and yes TM predicted\n",
    "        # a TM is predicted when the survival prediction is 0 at any point in the shot. Check if better results when TM is consecutive 0s\n",
    "        for j, shot_index in enumerate(shot_indices[:-1]):\n",
    "            survival_prediction = out_survival[:,i]\n",
    "            survival_prediction = (survival_prediction < threshold).astype(int)\n",
    "            tm = (0 in survival_prediction[shot_indices[j]:shot_indices[j+1]])\n",
    "            if normed_e[shot_index] == 1 and tm:\n",
    "                tm_prediction_per_shot.append(1)\n",
    "            elif normed_e[shot_index] == 1 and not tm:\n",
    "                tm_prediction_per_shot.append(0)\n",
    "            elif normed_e[shot_index] == 0 and not tm:\n",
    "                tm_prediction_per_shot.append(-1)\n",
    "            elif normed_e[shot_index] == 0 and tm:\n",
    "                tm_prediction_per_shot.append(-2)\n",
    "        fnr = tm_prediction_per_shot.count(0) / (tm_prediction_per_shot.count(1) + tm_prediction_per_shot.count(0))\n",
    "        fpr = tm_prediction_per_shot.count(-2) / (tm_prediction_per_shot.count(-1) + tm_prediction_per_shot.count(-2))\n",
    "        fnrs.append(fnr)\n",
    "        fprs.append(fpr)\n",
    "    auc_fnr = np.trapz(fnrs, prediction_times)\n",
    "    auc_fpr = np.trapz(fprs, prediction_times)\n",
    "    return auc_fpr, auc_fnr, fprs, fnrs, prediction_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_times = [20, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('survival.pkl', 'rb') as f:\n",
    "    out_survival = pickle.load(f)\n",
    "with open('models.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "model = loaded_model[8][0]\n",
    "out_survival = model.predict_survival(x_test_df, prediction_times)\n",
    "peaks = find_peaks_in_data(t_test)\n",
    "for i in range(0, 3):\n",
    "    peak_number = 140 + i\n",
    "    start_index = peaks[peak_number]\n",
    "    end_index = peaks[peak_number + 1]\n",
    "    times = np.arange(0, (end_index - start_index)*20, 20)\n",
    "    plt.plot(times, out_survival[start_index:end_index,2], label='Survival in 100ms')\n",
    "    plt.plot(times, out_survival[start_index:end_index,3], label='Survival in 200ms')\n",
    "\n",
    "    if (e_test[start_index]==1):\n",
    "        plt.title('YES TM')\n",
    "    else:\n",
    "        plt.title('NO TM')\n",
    "    plt.xlabel('Time / ms')\n",
    "    plt.ylabel('Survival probability')\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf8585/TMPredictor/survival_tm/auton-survival/auton_survival/estimators.py:206: FutureWarning: DataFrame.interpolate with method=bfill is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  return survival_predictions.sort_index(axis=0).interpolate().interpolate(method='bfill').T[times].values\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "#fpr_auc, fprs, prediction_times = fpr_auc(model, x_test_df, t_test, e_test, prediction_times, threshold=threshold)\n",
    "fpr_auc, fnr_auc, fprs, fnrs, predicted_times = fnr_auc(model, x_test_df, t_test, e_test, prediction_times, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.9627143922446 1.358695652173913\n",
      "[1.0, 1.0, 1.0, 0.9992542878448919]\n",
      "[0.0, 0.0, 0.0015527950310559005, 0.024844720496894408]\n"
     ]
    }
   ],
   "source": [
    "print(fpr_auc, fnr_auc)\n",
    "print(fprs)\n",
    "print(fnrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
